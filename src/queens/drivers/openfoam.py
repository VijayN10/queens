#
# SPDX-License-Identifier: LGPL-3.0-or-later
# Copyright (c) 2024-2025, QUEENS contributors.
#
# This file is part of QUEENS.
#
# QUEENS is free software: you can redistribute it and/or modify it under the terms of the GNU
# Lesser General Public License as published by the Free Software Foundation, either version 3 of
# the License, or (at your option) any later version. QUEENS is distributed in the hope that it will
# be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details. You
# should have received a copy of the GNU Lesser General Public License along with QUEENS. If not,
# see <https://www.gnu.org/licenses/>.
#
"""Driver to run OpenFOAM simulations."""

import re
from pathlib import Path

from queens.drivers.jobscript import Jobscript
from queens.utils.logger_settings import log_init_args

_JOBSCRIPT_TEMPLATE_CONTAINER = """
#!/bin/bash
# OpenFOAM container execution script generated by QUEENS

cd "{{ case_dir }}"

{{ container_command }} -- bash -c "
    source {{ openfoam_bashrc }}
    
    if [ -f 'system/blockMeshDict' ]; then
        echo 'Generating mesh...'
        blockMesh
    fi
    
    if {{ check_mesh }}; then
        echo 'Checking mesh...'
        checkMesh
    fi
    
    {% if parallel and num_procs > 1 %}
    if [ -f 'system/decomposeParDict' ]; then
        decomposePar
    fi
    mpirun -np {{ num_procs }} {{ solver }} -parallel > {{ log_file }} 2>&1
    if [ -f 'system/decomposeParDict' ]; then
        reconstructPar
    fi
    {% else %}
    {{ solver }} > {{ log_file }} 2>&1
    {% endif %}
    
    echo 'OpenFOAM simulation completed!'
"
"""

_JOBSCRIPT_TEMPLATE_NATIVE = """
#!/bin/bash
# OpenFOAM native execution script generated by QUEENS

source {{ openfoam_bashrc }}
cd "{{ case_dir }}"

if [ -f "system/blockMeshDict" ]; then
    echo "Generating mesh..."
    blockMesh
fi

if {{ check_mesh }}; then
    echo "Checking mesh..."
    checkMesh
fi

{% if parallel and num_procs > 1 %}
if [ -f "system/decomposeParDict" ]; then
    decomposePar
fi
mpirun -np {{ num_procs }} {{ solver }} -parallel > {{ log_file }} 2>&1
if [ -f "system/decomposeParDict" ]; then
    reconstructPar
fi
{% else %}
{{ solver }} > {{ log_file }} 2>&1
{% endif %}

echo "OpenFOAM simulation completed!"
"""


class OpenFoam(Jobscript):
    """Driver to run OpenFOAM simulations."""

    @log_init_args
    def __init__(
        self,
        parameters,
        case_template_dir,
        solver="simpleFoam",
        parallel=False,
        num_procs=1,
        container_command=None,
        openfoam_bashrc="/opt/openfoam9/etc/bashrc",
        check_mesh=True,
        files_to_copy=None,
        data_processor=None,
        gradient_data_processor=None,
    ):
        """Initialize OpenFoam driver.

        Args:
            parameters (Parameters): Parameters object for UQ study
            case_template_dir (str, Path): Path to OpenFOAM case template directory
            solver (str): OpenFOAM solver name (default: simpleFoam)
            parallel (bool): Run simulation in parallel (default: False)
            num_procs (int): Number of processors for parallel execution
            container_command (str, optional): Container command for execution
            openfoam_bashrc (str): Path to OpenFOAM bashrc file
            check_mesh (bool): Run checkMesh before solving
            files_to_copy (list, optional): Additional files to copy to case directory
            data_processor (obj, optional): Data processor for results extraction
            gradient_data_processor (obj, optional): Data processor for gradient data
        """
        # Select template based on execution mode
        if container_command:
            jobscript_template = _JOBSCRIPT_TEMPLATE_CONTAINER
        else:
            jobscript_template = _JOBSCRIPT_TEMPLATE_NATIVE

        # Set up input templates from case template directory
        input_templates = self._setup_input_templates(case_template_dir)

        # Configure extra options for template rendering
        extra_options = {
            "solver": solver,
            "parallel": parallel,
            "num_procs": num_procs,
            "container_command": container_command or "",
            "openfoam_bashrc": openfoam_bashrc,
            "check_mesh": "true" if check_mesh else "false",
            "log_file": f"log.{solver}",
            "case_dir": ".",
        }

        # Set up files to copy - ensure entire case template structure is copied
        if files_to_copy is None:
            files_to_copy = []
        
        case_template_path = Path(case_template_dir)
        if case_template_path.exists():
            files_to_copy.append(str(case_template_path))

        super().__init__(
            parameters=parameters,
            input_templates=input_templates,
            jobscript_template=jobscript_template,
            executable=solver,
            files_to_copy=files_to_copy,
            data_processor=data_processor,
            gradient_data_processor=gradient_data_processor,
            extra_options=extra_options,
        )

    def _setup_input_templates(self, case_template_dir):
        """Set up input templates from case template directory."""
        case_path = Path(case_template_dir)
        input_templates = {}
        
        if not case_path.exists():
            raise FileNotFoundError(f"Case template directory not found: {case_template_dir}")
        
        # Find all .template files recursively
        template_files = list(case_path.rglob("*.template"))
        
        for template_file in template_files:
            relative_path = template_file.relative_to(case_path)
            
            # Remove .template extension for output filename
            output_relative_path = relative_path.with_suffix('')
            
            # Use the relative path as template key to maintain directory structure
            # but replace path separators with underscores for the key
            template_key = str(output_relative_path).replace("/", "_").replace("\\", "_")
            
            input_templates[template_key] = str(template_file)
        
        return input_templates

    def _manage_paths(self, job_id, experiment_dir):
        """Override to properly handle OpenFOAM directory structure.
        
        Args:
            job_id (int): Job ID.
            experiment_dir (Path): Path to QUEENS experiment directory.

        Returns:
            job_dir (Path): Path to job directory.
            output_dir (Path): Path to output directory.
            output_file (Path): Path to output file(s).
            input_files (dict): Dict with name and path of the input file(s).
            log_file (Path): Path to log file.
        """
        job_dir = experiment_dir / str(job_id)
        output_dir = job_dir / "output"
        output_dir.mkdir(parents=True, exist_ok=True)

        output_prefix = "output"
        output_file = output_dir / output_prefix
        log_file = output_dir / (output_prefix + ".log")

        input_files = {}
        for input_template_name, input_template_path in self.input_templates.items():
            # For OpenFOAM, convert the template key back to proper path structure
            # Convert "0_p" -> "0/p", "system_controlDict" -> "system/controlDict"
            if "_" in input_template_name:
                # Convert underscores back to path separators
                relative_output_path = input_template_name.replace("_", "/")
            else:
                relative_output_path = input_template_name
                
            # Create full path for the output file
            output_file_path = job_dir / relative_output_path
            
            # Ensure the directory exists
            output_file_path.parent.mkdir(parents=True, exist_ok=True)
            
            input_files[input_template_name] = output_file_path

        return job_dir, output_dir, output_file, input_files, log_file


class OpenFoamLogProcessor:
    """Data processor to extract results from OpenFOAM log files."""
    
    def __init__(self, log_file_pattern="log.*"):
        """Initialize the log processor.
        
        Args:
            log_file_pattern (str): Pattern to match log files
        """
        self.log_file_pattern = log_file_pattern
    
    def __call__(self, job_options):
        """Process OpenFOAM simulation results.
        
        Args:
            job_options: Job options containing output directory
            
        Returns:
            dict: Dictionary containing extracted results
        """
        results = {}
        output_dir = Path(job_options.output_dir)
        
        # Find log files
        log_files = list(output_dir.glob(self.log_file_pattern))
        if not log_files:
            case_dir = output_dir.parent
            log_files = list(case_dir.glob(self.log_file_pattern))
        
        if log_files:
            log_file = log_files[0]
            
            with open(log_file, 'r') as f:
                content = f.read()
            
            results['residuals'] = self._extract_residuals(content)
            results['converged'] = 'End' in content or 'SIMPLE solution converged' in content
            
            # Extract execution time
            time_match = re.search(r'ExecutionTime = ([\d.]+) s', content)
            if time_match:
                results['execution_time'] = float(time_match.group(1))
        
        return results
    
    def _extract_residuals(self, content):
        """Extract residual data from log content.
        
        Args:
            content (str): Log file content
            
        Returns:
            dict: Dictionary containing residual data
        """
        residuals = {}
        
        residual_patterns = {
            'p': r'Solving for p, Initial residual = ([\d.e-]+)',
            'Ux': r'Solving for Ux, Initial residual = ([\d.e-]+)',
            'Uy': r'Solving for Uy, Initial residual = ([\d.e-]+)',
            'Uz': r'Solving for Uz, Initial residual = ([\d.e-]+)',
        }
        
        for field, pattern in residual_patterns.items():
            matches = re.findall(pattern, content)
            if matches:
                residuals[field] = [float(m) for m in matches]
                residuals[f'{field}_final'] = float(matches[-1])
        
        return residuals


class OpenFoamFieldProcessor:
    """Data processor to extract field data from OpenFOAM results."""
    
    def __init__(self, fields=None, time_dirs=None):
        """Initialize the field processor.
        
        Args:
            fields (list): List of field names to extract (e.g., ['p', 'U'])
            time_dirs (list): List of time directories to process (e.g., ['0', '1', 'latest'])
        """
        self.fields = fields or ['p', 'U']
        self.time_dirs = time_dirs or ['latest']
    
    def __call__(self, job_options):
        """Process OpenFOAM field results.
        
        Args:
            job_options: Job options containing output directory
            
        Returns:
            dict: Dictionary containing extracted field data
        """
        results = {}
        case_dir = Path(job_options.output_dir).parent
        
        # Find time directories
        time_directories = self._find_time_directories(case_dir)
        
        for time_dir in time_directories:
            if 'latest' in self.time_dirs or time_dir.name in self.time_dirs:
                time_results = {}
                
                for field in self.fields:
                    field_file = time_dir / field
                    if field_file.exists():
                        time_results[field] = self._extract_field_statistics(field_file)
                
                results[f'time_{time_dir.name}'] = time_results
        
        return results
    
    def _find_time_directories(self, case_dir):
        """Find time directories in the case.
        
        Args:
            case_dir (Path): Path to OpenFOAM case directory
            
        Returns:
            list: List of time directory paths
        """
        time_dirs = []
        for item in case_dir.iterdir():
            if item.is_dir():
                try:
                    # Check if directory name can be converted to float (time directories)
                    float(item.name)
                    time_dirs.append(item)
                except ValueError:
                    # Not a time directory
                    continue
        
        # Sort by time value
        time_dirs.sort(key=lambda x: float(x.name))
        return time_dirs
    
    def _extract_field_statistics(self, field_file):
        """Extract basic statistics from a field file.
        
        Args:
            field_file (Path): Path to OpenFOAM field file
            
        Returns:
            dict: Dictionary containing field statistics
        """
        try:
            with open(field_file, 'r') as f:
                content = f.read()
            
            # Extract internal field values (simplified parsing)
            internal_field_match = re.search(r'internalField\s+uniform\s+([\d.e-]+)', content)
            if internal_field_match:
                return {
                    'uniform_value': float(internal_field_match.group(1)),
                    'type': 'uniform'
                }
            
            # For non-uniform fields, could add more sophisticated parsing
            return {'type': 'non-uniform', 'parsed': False}
            
        except Exception as e:
            return {'error': str(e), 'parsed': False}


class OpenFoamResidualProcessor:
    """Specialized data processor for monitoring OpenFOAM convergence."""
    
    def __init__(self, target_residual=1e-6, max_iterations=None):
        """Initialize the residual processor.
        
        Args:
            target_residual (float): Target residual for convergence
            max_iterations (int): Maximum number of iterations to consider
        """
        self.target_residual = target_residual
        self.max_iterations = max_iterations
    
    def __call__(self, job_options):
        """Process OpenFOAM residual data.
        
        Args:
            job_options: Job options containing output directory
            
        Returns:
            dict: Dictionary containing convergence analysis
        """
        log_processor = OpenFoamLogProcessor()
        log_results = log_processor(job_options)
        
        if 'residuals' not in log_results:
            return {'convergence_analysis': 'No residual data found'}
        
        residuals = log_results['residuals']
        analysis = {}
        
        for field, values in residuals.items():
            if isinstance(values, list) and len(values) > 0:
                analysis[field] = {
                    'initial': values[0],
                    'final': values[-1],
                    'converged': values[-1] < self.target_residual,
                    'iterations': len(values),
                    'reduction_factor': values[0] / values[-1] if values[-1] > 0 else float('inf')
                }
        
        # Overall convergence assessment
        converged_fields = [field for field, data in analysis.items() 
                          if isinstance(data, dict) and data.get('converged', False)]
        
        analysis['overall'] = {
            'converged': len(converged_fields) == len([k for k in analysis.keys() if k != 'overall']),
            'converged_fields': converged_fields,
            'target_residual': self.target_residual
        }
        
        return analysis